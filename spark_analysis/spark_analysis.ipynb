{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType\n",
    "from pyspark.sql.functions import split, col, explode, avg, sum, countDistinct, max, arrays_overlap, rank, regexp_replace, collect_list, size\n",
    "from pyspark.sql import Window\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"imdb\") \\\n",
    "    .master(\"local[3]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Part 1: analyze the data using the parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Time taken to process: 10.659643\n"
    }
   ],
   "source": [
    "parquet_file_load_start = datetime.now()\n",
    "\n",
    "base_hdfs = \"hdfs://localhost:9000/user/student/imdb_spark_output/\"\n",
    "name_df = spark.read.load(base_hdfs + \"name\").withColumnRenamed(\"known_for_tiltes\", \"known_for_titles\")\n",
    "title_akas_df = spark.read.load(base_hdfs + \"title_akas\")\n",
    "title_basics_df = spark.read.load(base_hdfs + \"title_basics\")\n",
    "title_crew_df = spark.read.load(base_hdfs + \"title_crew\")\n",
    "title_episode_df = spark.read.load(base_hdfs + \"title_episode\")\n",
    "title_principals_df = spark.read.load(base_hdfs + \"title_principals\")\n",
    "title_ratings_df = spark.read.load(base_hdfs + \"title_ratings\")\n",
    "\n",
    "parquet_file_load_time = (datetime.now()-parquet_file_load_start).total_seconds()\n",
    "print(\"Time taken to process: {}\".format(parquet_file_load_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the name of each actor and the average rating for the movies that they are known for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+---------+-------------------+-------------------------------------+-------------------------+---------+\n|nconst   |primary_name       |primary_profession                   |avg_rating_best_known_for|num_votes|\n+---------+-------------------+-------------------------------------+-------------------------+---------+\n|nm0000050|Groucho Marx       |[soundtrack, actor, writer]          |7.699999999999999        |107440   |\n|nm0001492|Kyle MacLachlan    |[actor, soundtrack, director]        |7.075                    |927748   |\n|nm0001585|Kelly Packard      |[actress, soundtrack]                |6.025                    |27881    |\n|nm0004713|Jodi Applegate Kay |[actress]                            |7.6                      |420899   |\n|nm0008344|Hikari Abe         |[actress]                            |6.7                      |12101    |\n|nm0009736|Miguel Aceves Mej√≠a|[actor, soundtrack, music_department]|6.25                     |5223     |\n|nm0010050|David Ackert       |[actor, producer, writer]            |7.3999999999999995       |20133    |\n|nm0014133|Paul Ahmarani      |[actor]                              |6.625                    |70562    |\n|nm0014266|Irja Aholainen     |[actress]                            |5.949999999999999        |203      |\n|nm0015621|Errol Akyalcin     |[actor]                              |6.8                      |126      |\n+---------+-------------------+-------------------------------------+-------------------------+---------+\nonly showing top 10 rows\n\nTime taken to process: 34.151825\n"
    }
   ],
   "source": [
    "parquet_actor_ratings_start_time = datetime.now()\n",
    "\n",
    "name_best_known_for = (\n",
    "    name_df.select('known_for_titles', 'primary_profession', 'nconst', 'primary_name', 'primary_profession')\n",
    "        .filter(\"known_for_titles is not null and arrays_overlap(primary_profession, array('actor', 'actress'))\")\n",
    "        .withColumn(\"tconst\", explode(\"known_for_titles\"))\n",
    "        .drop(\"known_for_titles\")\n",
    "        .join(title_ratings_df, 'tconst')\n",
    "        .groupBy('nconst', 'primary_name', 'primary_profession')\n",
    "        .agg(\n",
    "            avg('average_rating').alias('avg_rating_best_known_for'),\n",
    "            sum('num_votes').alias('num_votes')\n",
    "        )\n",
    ")\n",
    "name_best_known_for.show(10, False)\n",
    "parquet_actor_ratings_total_time = (datetime.now()-parquet_actor_ratings_start_time).total_seconds()\n",
    "print(\"Time taken to process: {}\".format(parquet_actor_ratings_total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the top rated episode from every TV show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_top_episode_start_time = datetime.now()\n",
    "\n",
    "episode_window = Window.partitionBy('parent_tconst').orderBy(col('num_votes').desc(), col('average_rating').desc())\n",
    "episode_rating = (\n",
    "    title_episode_df.join(title_ratings_df, 'tconst')\n",
    "        # .filter(\"parent_tconst = 'tt0108778'\")\n",
    "        .join(\n",
    "            title_basics_df.select('tconst', 'original_title')\n",
    "                .withColumnRenamed('tconst', 'parent_tconst')\n",
    "                .withColumnRenamed('original_title', 'series_title')\n",
    "            , 'parent_tconst'\n",
    "            , 'left'\n",
    "            )\n",
    "        .join(\n",
    "            title_basics_df.select('tconst', 'original_title')\n",
    "                .withColumnRenamed('original_title', 'episode_title')\n",
    "            , 'tconst'\n",
    "            , 'left'\n",
    "            )\n",
    "        .withColumn('ranks', rank().over(episode_window))\n",
    "        .filter('ranks = 1')\n",
    "        .drop('ranks')\n",
    ")\n",
    "episode_rating.show(10, False)\n",
    "parquet_top_episode_total_time = (datetime.now()-parquet_top_episode_start_time).total_seconds()\n",
    "print(\"Time taken to process: {}\".format(parquet_crew_total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Count of crew members for each title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+---------+---------+-------+-----+-------+---------------+-------------+----+\n|tconst   |directors|writers|actor|actress|archive_footage|archive_sound|self|\n+---------+---------+-------+-----+-------+---------------+-------------+----+\n|tt0000658|1        |-1     |null |null   |null           |null         |null|\n|tt0000839|1        |-1     |null |null   |null           |null         |null|\n|tt0001170|1        |1      |3    |1      |null           |null         |null|\n|tt0001581|1        |-1     |null |null   |null           |null         |null|\n|tt0001664|1        |-1     |2    |1      |null           |null         |null|\n|tt0001732|1        |-1     |4    |2      |null           |null         |null|\n|tt0001887|1        |-1     |null |null   |null           |null         |null|\n|tt0002253|1        |1      |4    |2      |null           |null         |null|\n|tt0002347|1        |-1     |null |null   |null           |null         |null|\n|tt0002473|1        |1      |3    |4      |null           |null         |null|\n+---------+---------+-------+-----+-------+---------------+-------------+----+\nonly showing top 10 rows\n\nTime taken to process: 41.034453\n"
    }
   ],
   "source": [
    "parquet_crew_start_time = datetime.now()\n",
    "crew_count = (\n",
    "    title_crew_df.withColumn(\"cd\", size('directors'))\n",
    "        .withColumn('cw', size('writers'))\n",
    "        .drop('directors', 'writers')\n",
    "        .withColumnRenamed('cw', 'writers')\n",
    "        .withColumnRenamed('cd', 'directors')\n",
    "        .join(title_principals_df.groupBy('tconst').pivot('category').count(), 'tconst', 'left')\n",
    ")\n",
    "crew_count.show(10, False)\n",
    "parquet_crew_total_time = (datetime.now()-parquet_crew_start_time).total_seconds()\n",
    "print(\"Time taken to process: {}\".format(parquet_crew_total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Part 2: analyze the data using the TSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Time taken to process: 319.170284\n"
    }
   ],
   "source": [
    "tsv_file_load_start = datetime.now()\n",
    "\n",
    "tsv_name =  (\n",
    "    spark.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .option(\"nullValue\", \"\\\\N\")\\\n",
    "        .load(\"hdfs://localhost:9000/user/student/imdb_tsv/name.basics.tsv.gz\")\\\n",
    "        .withColumn(\"primary_profession\", split(col(\"primaryProfession\"), \",\").cast(\"array<string>\"))\\\n",
    "        .withColumn(\"known_for_titles\", split(col(\"knownForTitles\"), \",\").cast(\"array<string>\"))\\\n",
    "        .withColumnRenamed(\"primaryName\", \"primary_name\")\\\n",
    "        .withColumnRenamed(\"birthYear\", \"birth_year\")\\\n",
    "        .withColumnRenamed(\"deathYear\", \"death_year\")\\\n",
    "        .drop(\"primaryProfession\", \"knownForTitles\")\n",
    ")\n",
    "\n",
    "tsv_title_aka = (\n",
    "    spark.read.format(\"com.databricks.spark.csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"nullValue\", \"\\\\N\")\n",
    "        .load(\"hdfs://localhost:9000/user/student/imdb_tsv/title.akas.tsv.gz\")\n",
    "        .withColumnRenamed(\"titleId\", \"title_id\")\n",
    "        .withColumnRenamed(\"isOriginalTitle\", \"is_original_title\")\n",
    ")\n",
    "\n",
    "tsv_title_basics = (\n",
    "    spark.read.format(\"com.databricks.spark.csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"nullValue\", \"\\\\N\")\n",
    "        .option(\"quote\", \"\")\n",
    "        .load(\"hdfs://localhost:9000/user/student/imdb_tsv/title.basics.tsv.gz\")\n",
    "        .withColumnRenamed(\"titleType\", \"title_type\")\n",
    "        .withColumnRenamed(\"primaryTitle\", \"primary_title\")\n",
    "        .withColumnRenamed(\"originalTitle\", \"original_title\")\n",
    "        .withColumnRenamed(\"isAdult\", \"is_adult\")\n",
    "        .withColumnRenamed(\"startYear\", \"start_year\")\n",
    "        .withColumnRenamed(\"endYear\", \"end_year\")\n",
    "        .withColumnRenamed(\"runtimeMinutes\", \"runtime_minutes\")\n",
    "        .withColumn(\"genre_list\", split(col(\"genres\"), \",\").cast(\"array<string>\"))\n",
    "        .drop(\"genres\")\n",
    "        .withColumnRenamed(\"genre_list\", \"genres\")\n",
    ")\n",
    "\n",
    "tsv_title_crew = (\n",
    "    spark.read.format(\"com.databricks.spark.csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"nullValue\", \"\\\\N\")\n",
    "        .option(\"quote\", \"\")\n",
    "        .load(\"hdfs://localhost:9000/user/student/imdb_tsv/title.crew.tsv.gz\")\n",
    "        .withColumn(\"directors_list\", split(col(\"directors\"), \",\").cast(\"array<string>\"))\n",
    "        .withColumn(\"writers_list\", split(col(\"writers\"), \",\").cast(\"array<string>\"))\n",
    "        .drop(\"directors\", \"writers\")\n",
    "        .withColumnRenamed(\"directors_list\", \"directors\")\n",
    "        .withColumnRenamed(\"writers_list\", \"writers\")\n",
    ")\n",
    "\n",
    "tsv_title_episode = (\n",
    "    spark.read.format(\"com.databricks.spark.csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"nullValue\", \"\\\\N\")\n",
    "        .option(\"quote\", \"\")\n",
    "        .load(\"hdfs://localhost:9000/user/student/imdb_tsv/title.episode.tsv.gz\")\n",
    "        .withColumnRenamed(\"parentTconst\", \"parent_tconst\")\n",
    ")\n",
    "\n",
    "tsv_title_principal = (\n",
    "    spark.read.format(\"com.databricks.spark.csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"nullValue\", \"\\\\N\")\n",
    "        .option(\"quote\", \"\")\n",
    "        .load(\"hdfs://localhost:9000/user/student/imdb_tsv/title.principals.tsv.gz\")\n",
    "        .withColumn(\"characters_exploded\", explode(split( regexp_replace(col(\"characters\"), r'\\[|\\]', '')   , '\",\"').cast(\"array<string>\")))\n",
    "        .withColumn(\"characters_clean\", regexp_replace(col(\"characters_exploded\"), r'\\\"', ''))\n",
    "        .groupBy(\"tconst\",\"ordering\", \"nconst\", \"category\", \"job\", \"characters\")\n",
    "        .agg(collect_list(\"characters_clean\").alias(\"characters_array\"))\n",
    "        .drop(\"characters\")\n",
    "        .withColumnRenamed(\"characters_exploded\", \"characters\")\n",
    ")\n",
    "\n",
    "tsv_title_rating = (\n",
    "    spark.read.format(\"com.databricks.spark.csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"nullValue\", \"\\\\N\")\n",
    "        .option(\"quote\", \"\")\n",
    "        .load(\"hdfs://localhost:9000/user/student/imdb_tsv/title.ratings.tsv.gz\")\n",
    "        .withColumnRenamed(\"averageRating\", \"average_rating\")\n",
    "        .withColumnRenamed(\"numVotes\", \"num_votes\")\n",
    ")\n",
    "\n",
    "tsv_file_load_time = (datetime.now()-tsv_file_load_start).total_seconds()\n",
    "print(\"Time taken to process: {}\".format(tsv_file_load_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the name of each actor and the average rating for the movies that they are known for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+---------+-----------------+---------------------------------+-------------------------+---------+\n|nconst   |primary_name     |primary_profession               |avg_rating_best_known_for|num_votes|\n+---------+-----------------+---------------------------------+-------------------------+---------+\n|nm0000050|Groucho Marx     |[soundtrack, actor, writer]      |7.699999999999999        |107440   |\n|nm0000205|Parker Posey     |[actress, soundtrack, writer]    |6.225                    |601966   |\n|nm0000295|Kate Beckinsale  |[actress, producer, soundtrack]  |6.575                    |822675   |\n|nm0001316|Oliver Hardy     |[actor, soundtrack, director]    |7.125                    |16775    |\n|nm0001492|Kyle MacLachlan  |[actor, soundtrack, director]    |7.075                    |927748   |\n|nm0001585|Kelly Packard    |[actress, soundtrack]            |6.025                    |27881    |\n|nm0001710|David Schwimmer  |[actor, director, soundtrack]    |7.725                    |1218722  |\n|nm0003813|Liselotte Pulver |[actress, soundtrack]            |6.8                      |19602    |\n|nm0003944|Ian James Corlett|[actor, writer, music_department]|7.324999999999999        |286903   |\n|nm0004005|Marklen Kennedy  |[producer, actor, writer]        |3.1                      |1057     |\n+---------+-----------------+---------------------------------+-------------------------+---------+\nonly showing top 10 rows\n\nTime taken to process: 95.98023\n"
    }
   ],
   "source": [
    "tsv_actor_ratings_start_time = datetime.now()\n",
    "\n",
    "tsv_name_best_known_for = (\n",
    "    tsv_name.select('known_for_titles', 'primary_profession', 'nconst', 'primary_name', 'primary_profession')\n",
    "        .filter(\"known_for_titles is not null and arrays_overlap(primary_profession, array('actor', 'actress'))\")\n",
    "        .withColumn(\"tconst\", explode(\"known_for_titles\"))\n",
    "        .drop(\"known_for_titles\")\n",
    "        .join(tsv_title_rating, 'tconst')\n",
    "        .groupBy('nconst', 'primary_name', 'primary_profession')\n",
    "        .agg(\n",
    "            avg('average_rating').alias('avg_rating_best_known_for'),\n",
    "            sum('num_votes').alias('num_votes')\n",
    "        )\n",
    ")\n",
    "tsv_name_best_known_for.show(10, False)\n",
    "tsv_actor_ratings_total_time = (datetime.now()-tsv_actor_ratings_start_time).total_seconds()\n",
    "print(\"Time taken to process: {}\".format(tsv_actor_ratings_total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the top rated episode from every TV show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+---------+-------------+------------+-------------+--------------+---------+------------------------------+--------------------+\n|tconst   |parent_tconst|seasonNumber|episodeNumber|average_rating|num_votes|series_title                  |episode_title       |\n+---------+-------------+------------+-------------+--------------+---------+------------------------------+--------------------+\n|tt0613146|tt0051286    |1           |1            |7.8           |5        |Ivanhoe                       |Freeing the Serfs   |\n|tt0593904|tt0061259    |1           |7            |7.9           |28       |The Guns of Will Sonnett      |A Son for a Son     |\n|tt0624468|tt0062578    |1           |1            |7.5           |92       |Land of the Giants            |The Crash           |\n|tt0074772|tt0075524    |1           |0            |6.5           |19       |Lanigan's Rabbi               |Pilot               |\n|tt0514281|tt0078562    |2           |1            |8.4           |50       |Archie Bunker's Place         |Archie Alone: Part 1|\n|tt1323151|tt0078590    |1           |1            |7.1           |7        |Crime and Punishment          |Part 1              |\n|tt0080263|tt0079902    |1           |2            |8.4           |2253     |Sherlok Kholms i doktor Vatson|Krovavaya nadpis    |\n|tt0751811|tt0080306    |1           |1            |8.1           |252      |Yes Minister                  |Open Government     |\n|tt2341013|tt0086779    |1           |1            |8.3           |55       |La piovra                     |Episode #1.1        |\n|tt1092449|tt0090402    |1           |1            |7.1           |15       |Bread                         |Episode #1.1        |\n+---------+-------------+------------+-------------+--------------+---------+------------------------------+--------------------+\nonly showing top 10 rows\n\nTime taken to process: 100.308339\n"
    }
   ],
   "source": [
    "tsv_top_episode_start_time = datetime.now()\n",
    "\n",
    "tsv_episode_window = Window.partitionBy('parent_tconst').orderBy(col('num_votes').desc(), col('average_rating').desc())\n",
    "tsv_episode_rating = (\n",
    "    tsv_title_episode.join(tsv_title_rating, 'tconst')\n",
    "        .join(\n",
    "            tsv_title_basics.select('tconst', 'original_title')\n",
    "                .withColumnRenamed('tconst', 'parent_tconst')\n",
    "                .withColumnRenamed('original_title', 'series_title')\n",
    "            , 'parent_tconst'\n",
    "            , 'left'\n",
    "            )\n",
    "        .join(\n",
    "            tsv_title_basics.select('tconst', 'original_title')\n",
    "                .withColumnRenamed('original_title', 'episode_title')\n",
    "            , 'tconst'\n",
    "            , 'left'\n",
    "            )\n",
    "        .withColumn('ranks', rank().over(tsv_episode_window))\n",
    "        .filter('ranks = 1')\n",
    "        .drop('ranks')\n",
    ")\n",
    "tsv_episode_rating.show(10, False)\n",
    "tsv_top_episode_total_time = (datetime.now()-tsv_top_episode_start_time).total_seconds()\n",
    "print(\"Time taken to process: {}\".format(tsv_top_episode_total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Count of crew members for each title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+---------+---------+-------+-----+-------+---------------+-------------+----+\n|tconst   |directors|writers|actor|actress|archive_footage|archive_sound|self|\n+---------+---------+-------+-----+-------+---------------+-------------+----+\n|tt0000658|1        |-1     |null |null   |null           |null         |null|\n|tt0000839|1        |-1     |null |null   |null           |null         |null|\n|tt0001170|1        |1      |3    |1      |null           |null         |null|\n|tt0001581|1        |-1     |null |null   |null           |null         |null|\n|tt0001664|1        |-1     |2    |1      |null           |null         |null|\n|tt0001732|1        |-1     |4    |2      |null           |null         |null|\n|tt0001887|1        |-1     |null |null   |null           |null         |null|\n|tt0002253|1        |1      |4    |2      |null           |null         |null|\n|tt0002347|1        |-1     |null |null   |null           |null         |null|\n|tt0002473|1        |1      |3    |4      |null           |null         |null|\n+---------+---------+-------+-----+-------+---------------+-------------+----+\nonly showing top 10 rows\n\nTime taken to process: 726.72443\n"
    }
   ],
   "source": [
    "tsv_crew_start_time = datetime.now()\n",
    "tsv_crew_count = (\n",
    "    tsv_title_crew.withColumn(\"cd\", size('directors'))\n",
    "        .withColumn('cw', size('writers'))\n",
    "        .drop('directors', 'writers')\n",
    "        .withColumnRenamed('cw', 'writers')\n",
    "        .withColumnRenamed('cd', 'directors')\n",
    "        .join(tsv_title_principal.groupBy('tconst').pivot('category').count(), 'tconst', 'left')\n",
    "    )\n",
    "tsv_crew_count.show(10, False)\n",
    "tsv_crew_total_time = (datetime.now()-tsv_crew_start_time).total_seconds()\n",
    "print(\"Time taken to process: {}\".format(tsv_crew_total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                    Task     Parquet          TSV\n0       Avg Actor Rating   34.151825    95.980230\n1      Top Rated Episode   29.295635   100.308339\n2     Count Crew Members   41.034453   726.724430\n3           File Loading   10.659643   319.170284\n4  Total Processing Time  104.481913   923.012999\n5     Overall Total Time  115.141556  1242.183283",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Task</th>\n      <th>Parquet</th>\n      <th>TSV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Avg Actor Rating</td>\n      <td>34.151825</td>\n      <td>95.980230</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Top Rated Episode</td>\n      <td>29.295635</td>\n      <td>100.308339</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Count Crew Members</td>\n      <td>41.034453</td>\n      <td>726.724430</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>File Loading</td>\n      <td>10.659643</td>\n      <td>319.170284</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Total Processing Time</td>\n      <td>104.481913</td>\n      <td>923.012999</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Overall Total Time</td>\n      <td>115.141556</td>\n      <td>1242.183283</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "time_result = pd.DataFrame(\n",
    "    columns=['Task', 'Parquet', 'TSV'],\n",
    "    data=[['Avg Actor Rating', parquet_actor_ratings_total_time, tsv_actor_ratings_total_time],\n",
    "            ['Top Rated Episode', parquet_top_episode_total_time, tsv_top_episode_total_time],\n",
    "            ['Count Crew Members',parquet_crew_total_time, tsv_crew_total_time ],\n",
    "            ['File Loading', parquet_file_load_time, tsv_file_load_time],\n",
    "            [\n",
    "                'Total Processing Time',\n",
    "                parquet_actor_ratings_total_time + parquet_top_episode_total_time + parquet_crew_total_time,\n",
    "                tsv_actor_ratings_total_time + tsv_top_episode_total_time + tsv_crew_total_time\n",
    "            ],\n",
    "            [\n",
    "                'Overall Total Time',\n",
    "                parquet_actor_ratings_total_time + parquet_top_episode_total_time + parquet_crew_total_time + parquet_file_load_time,\n",
    "                tsv_actor_ratings_total_time + tsv_top_episode_total_time + tsv_crew_total_time + tsv_file_load_time\n",
    "            ]\n",
    "    ])\n",
    "display(time_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                    Task     Parquet          TSV\n0       Avg Actor Rating   43.629378    90.497702\n1      Top Rated Episode   41.142197    60.247065\n2     Count Crew Members   53.458683   827.916913\n3           File Loading    7.298965   315.670217\n4  Total Processing Time  138.230258   978.661680\n5     Overall Total Time  145.529223  1294.331897",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Task</th>\n      <th>Parquet</th>\n      <th>TSV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Avg Actor Rating</td>\n      <td>43.629378</td>\n      <td>90.497702</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Top Rated Episode</td>\n      <td>41.142197</td>\n      <td>60.247065</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Count Crew Members</td>\n      <td>53.458683</td>\n      <td>827.916913</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>File Loading</td>\n      <td>7.298965</td>\n      <td>315.670217</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Total Processing Time</td>\n      <td>138.230258</td>\n      <td>978.661680</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Overall Total Time</td>\n      <td>145.529223</td>\n      <td>1294.331897</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "time_result = pd.DataFrame(\n",
    "    columns=['Task', 'Parquet', 'TSV'],\n",
    "    data=[['Avg Actor Rating', parquet_actor_ratings_total_time, tsv_actor_ratings_total_time],\n",
    "            ['Top Rated Episode', parquet_top_episode_total_time, tsv_top_episode_total_time],\n",
    "            ['Count Crew Members',parquet_crew_total_time, tsv_crew_total_time ],\n",
    "            ['File Loading', parquet_file_load_time, tsv_file_load_time],\n",
    "            [\n",
    "                'Total Processing Time',\n",
    "                parquet_actor_ratings_total_time + parquet_top_episode_total_time + parquet_crew_total_time,\n",
    "                tsv_actor_ratings_total_time + tsv_top_episode_total_time + tsv_crew_total_time\n",
    "            ],\n",
    "            [\n",
    "                'Overall Total Time',\n",
    "                parquet_actor_ratings_total_time + parquet_top_episode_total_time + parquet_crew_total_time + parquet_file_load_time,\n",
    "                tsv_actor_ratings_total_time + tsv_top_episode_total_time + tsv_crew_total_time + tsv_file_load_time\n",
    "            ]\n",
    "    ])\n",
    "display(time_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit",
   "language": "python",
   "name": "python36764bite1ac5a9d5a2c4082bd9aec9a7551e950"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}